{"cells":[{"cell_type":"markdown","source":["<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"> <img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\"/> </a> <br/> This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"> Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. </a>"],"metadata":{}},{"cell_type":"markdown","source":["### Spark Simple Random Forest Model Tutorial\n### Sohel Khan\n\n#### This is an introductory tutorial"],"metadata":{}},{"cell_type":"markdown","source":["### The origin of data is http://archive.ics.uci.edu/ml/"],"metadata":{}},{"cell_type":"code","source":["target_url = (\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\") \nimport pandas as pd\nwine = pd.read_csv( target_url, header = 0, sep =\";\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["wine.head()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Convert data from Pandas DataFrame to PySpark SQL DataFrame"],"metadata":{}},{"cell_type":"code","source":["raw_data_df = sqlContext.createDataFrame(wine)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["raw_data_df.count()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["raw_data_df.show(3)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Explore the Data"],"metadata":{}},{"cell_type":"code","source":["# In this raw data point, 2001.0 is the label, and the remaining values are features\nprint raw_data_df.count()\nraw_data_df.show(3)\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["raw_data_df.select(\"fixed acidity\", \"residual sugar\",\"alcohol\",\"quality\").show(3)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Transform Data to LabeledPoint"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nimport numpy as np\nfrom pyspark.sql import functions as sql_functions\n\ndef create_label_point_function(df):\n   \n    \n    return (df\n            .select(\"quality\", \"alcohol\",\"density\",\"fixed acidity\")\n            .map(lambda x: LabeledPoint(x[0], x[1:]))\n            .toDF())\n\n  \nlabel_points_df = create_label_point_function(raw_data_df)\n\nfirst_point_features = label_points_df.first().features\nfirst_point_label = label_points_df.first().label\nprint first_point_features, first_point_label"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["label_points_df.show(3, truncate=True)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Perform \"feature engineering\"\n[PolynomialExpansion](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import PolynomialExpansion\npolynomial_expansion = PolynomialExpansion(degree=2, inputCol=\"features\", outputCol=\"polyFeatures\") # feature transformation"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### Sample the Data: Training, validation, and test sets\n\nUse the [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit)"],"metadata":{}},{"cell_type":"code","source":["\nweights = [.8, .1, .1]\nseed = 42\ntrain_data_df, val_data_df, test_data_df = label_points_df.randomSplit(weights, seed)\n\n\n\n\ntrain_data_df.cache()\nval_data_df.cache()\ntest_data_df.cache()\n\n\n\nn_train = train_data_df.count()\nn_val = val_data_df.count()\nn_test = test_data_df.count()\n\nprint n_train, n_val, n_test, n_train + n_val + n_test\nprint label_points_df.count()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["### Let's try Random Simple Forest Model\nhttps://spark.apache.org/docs/latest/ml-classification-regression.html\n\nhttps://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import RandomForestRegressor\n\nrandom_forest_model = RandomForestRegressor(featuresCol='polyFeatures')"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["### Execute Piplelined Model\n\n[Pipeline](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[polynomial_expansion,random_forest_model])  #create the pipleline\n\npipeline_model = pipeline.fit(train_data_df)  #develop pipleine model with train data\n\npredictions_df = pipeline_model.transform(test_data_df) #predict with test data\n"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### Evaluate the Model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator()\nrmse_test_pipeline = evaluator.evaluate(predictions_df, {evaluator.metricName: \"rmse\"})\nprint('RMSE for test data set using pipelines: {0:.3f}'.format(rmse_test_pipeline))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["def squared_error(label, prediction):\n    \"\"\"Calculates the squared error for a single prediction.\"\"\"\n    return float((label - prediction)**2)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["predictions = np.asarray(predictions_df\n                         .select('prediction')\n                         .collect())\nactual = np.asarray(predictions_df\n                      .select('label')\n                      .collect())\nerror = np.asarray(predictions_df\n                     .rdd\n                     .map(lambda lp: squared_error(lp.label, lp.prediction))\n                     .collect())"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["print 'prediction maximum:' , max(predictions)\nprint 'actual maximum:', max(actual)\nprint 'maximum error:', max(error)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Draw Simple Plot"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nx_points = np.arange(0, len(predictions))\nfigsize=(10.5, 6)\nfig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\nplt.scatter(x_points, predictions, c='r',  label='Predictions')\nplt.scatter(x_points, actual, c='g', label = 'Actual')\nax.set_xlabel('Wine bottle #'), ax.set_ylabel(r'Quality')\nplt.legend()\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### What's went wrong??"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32}],"metadata":{"name":"3_Wine_Study_Simple_Random_Forest_Part1","notebookId":3192501604641407},"nbformat":4,"nbformat_minor":0}
